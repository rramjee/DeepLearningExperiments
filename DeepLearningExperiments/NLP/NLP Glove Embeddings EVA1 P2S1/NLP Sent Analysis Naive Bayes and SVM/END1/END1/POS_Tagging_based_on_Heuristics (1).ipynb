{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS Tagging based on Heuristics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM0Ka5OWjTtn"
      },
      "source": [
        "##Import necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUkH-XafjF18",
        "cellView": "both",
        "outputId": "0a724a71-3f69-490f-de02-ab247fc9978f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.chunk import ne_chunk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnfJWQfEjn89"
      },
      "source": [
        "## A sentence under consideration for Information Extraction (NER)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nOjV-QMjlBF"
      },
      "source": [
        "sentence = 'Virat Kohli is an Indian cricketer who currently captains the India national team. A right-handed top-order batsman, Kohli is regarded as one of the best batsmen in the world'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwc64Wajjv95"
      },
      "source": [
        "## Apply word tokenization and part-of-speech tagging to the sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrJPkc2MjtwW"
      },
      "source": [
        "def preprocess(sent):\n",
        "    sent =  word_tokenize(sent)\n",
        "    sent = pos_tag(sent)\n",
        "    return sent"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKv51GotjyZU",
        "outputId": "6678f999-74c3-4ba2-dac5-c2739fbed8a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "sent = preprocess(sentence)\n",
        "sent"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Virat', 'NNP'),\n",
              " ('Kohli', 'NNP'),\n",
              " ('is', 'VBZ'),\n",
              " ('an', 'DT'),\n",
              " ('Indian', 'JJ'),\n",
              " ('cricketer', 'NN'),\n",
              " ('who', 'WP'),\n",
              " ('currently', 'RB'),\n",
              " ('captains', 'VBZ'),\n",
              " ('the', 'DT'),\n",
              " ('India', 'NNP'),\n",
              " ('national', 'JJ'),\n",
              " ('team', 'NN'),\n",
              " ('.', '.'),\n",
              " ('A', 'DT'),\n",
              " ('right-handed', 'JJ'),\n",
              " ('top-order', 'NN'),\n",
              " ('batsman', 'NN'),\n",
              " (',', ','),\n",
              " ('Kohli', 'NNP'),\n",
              " ('is', 'VBZ'),\n",
              " ('regarded', 'VBN'),\n",
              " ('as', 'IN'),\n",
              " ('one', 'CD'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('best', 'JJS'),\n",
              " ('batsmen', 'NNS'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('world', 'NN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZfnCIBOlP32"
      },
      "source": [
        "## Plot a Parse Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed8JxUUVfMzB",
        "outputId": "502cea7f-97f4-40ed-9f42-35d6a63e9cd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "from nltk.parse import ShiftReduceParser\n",
        "pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
        "NPChunker = ShiftReduceParser(pattern)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f8b259d30781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShiftReduceParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'NP: {<DT>?<JJ>*<NN>}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mNPChunker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShiftReduceParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/parse/shiftreduce.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, grammar, trace)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_grammar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/parse/shiftreduce.py\u001b[0m in \u001b[0;36m_check_grammar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mproductions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproductions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# Any production whose RHS is an extension of another production's RHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'productions'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9w_5C8QcpmZ",
        "outputId": "74b05652-c76c-4778-8e2f-d4efcefaf9fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
        "NPChunker =  # Regex Parse using the pattern\n",
        "result = NPChunker.parse(sent)\n",
        "result.draw()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-e2e442e7c134>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    NPChunker =  # Regex Parse using the pattern\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PPhX8NKSvp7"
      },
      "source": [
        "print(tree)\n",
        "result = NPChunker.parse(sent)\n",
        "result.draw()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SFMBOJhj0kD",
        "outputId": "dc4e14fe-ad03-4892-e575-02c4551c25b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "import re\n",
        "pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
        "pattern = nltk.CFG.fromstring(pattern)\n",
        "NPChunker = nltk.ChartParser(pattern)\n",
        "for tree in parser.parse(sent):\n",
        "  print(tree)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mread_grammar\u001b[0;34m(input, nonterm_parser, probabilistic, encoding)\u001b[0m\n\u001b[1;32m   1286\u001b[0m                 \u001b[0;31m# expand out the disjunctions on the RHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m                 \u001b[0mproductions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_read_production\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonterm_parser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilistic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/grammar.py\u001b[0m in \u001b[0;36m_read_production\u001b[0;34m(line, nonterm_parser, probabilistic)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ARROW_RE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected an arrow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m     \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected an arrow",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-06f28d2a21f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'NP: {<DT>?<JJ>*<NN>}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mNPChunker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChartParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mfromstring\u001b[0;34m(cls, input, encoding)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \"\"\"\n\u001b[1;32m    535\u001b[0m         start, productions = read_grammar(input, standard_nonterm_parser,\n\u001b[0;32m--> 536\u001b[0;31m                                           encoding=encoding)\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproductions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mread_grammar\u001b[0;34m(input, nonterm_parser, probabilistic, encoding)\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m             raise ValueError('Unable to parse line %s: %s\\n%s' %\n\u001b[0;32m-> 1290\u001b[0;31m                              (linenum+1, line, e))\n\u001b[0m\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproductions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to parse line 1: NP: {<DT>?<JJ>*<NN>}\nExpected an arrow"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzfWmM0s3qLQ"
      },
      "source": [
        "## POS Tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lUv0-IX0V-v"
      },
      "source": [
        "from nltk.chunk import conlltags2tree, tree2conlltags\n",
        "from pprint import pprint\n",
        "iob_tagged = tree2conlltags(cs)\n",
        "pprint(iob_tagged)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsWTk0dX4DN8"
      },
      "source": [
        "**This is how Information is extracted using heuristics based techniques. Try using another pattern.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGPurTlb3tWd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}